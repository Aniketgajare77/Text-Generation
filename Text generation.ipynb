{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1KBwUopfMycfI13p-uQ0M_m2RDyO_v0Zc","authorship_tag":"ABX9TyM9FXnYYX8FLbJDVisX4N36"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install tensorflow-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkvp6VPwq6yF","executionInfo":{"status":"ok","timestamp":1707394986164,"user_tz":-330,"elapsed":1358,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"b4bdec94-8705-4ea3-f63f-794d563e5d91"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow-gpu\n","  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n"]}]},{"cell_type":"code","source":["data=\"\"\"Received November 17, 2020, accepted November 30, 2020, date of publication December 4, 2020,\n","date of current version December 17, 2020.\n","Digital Object Identifier 10.1109/ACCESS.2020.3042604\n","Automatic Classification of Sexism in Social\n","Networks: An Empirical Study on Twitter Data\n","FRANCISCO RODRÍGUEZ-SÁNCHEZ , JORGE CARRILLO-DE-ALBORNOZ, AND LAURA PLAZA\n","NLP & IR Group, UNED, 28040 Madrid, Spain\n","Corresponding author: Francisco Rodríguez-Sánchez (frodriguez.sanchez@invi.uned.es)\n","This work was supported by the Spanish Ministry of Science and Innovation under Project Misinformation and Miscommunication in\n","Social Media (PGC2018-096212-B-C32).\n","ABSTRACT During the last decade, hateful and sexist content towards women is being increasingly spread\n","on social networks. The exposure to sexist speech has serious consequences to women’s life and limits\n","their freedom of speech. Previous studies have focused on identifying hatred or violence towards women.\n","However, sexism is expressed in very different forms: it includes subtle stereotypes and attitudes that,\n","although frequently unnoticed, are extremely harmful for both women and society. In this work, we propose a\n","new task that aims to understand and analyze how sexism, from explicit hate or violence to subtle expressions,\n","is expressed in online conversations. To this end, we have developed and released the first dataset of sexist\n","expressions and attitudes in Twitter in Spanish (MeTwo) and investigate the feasibility of using machine\n","learning techniques (both traditional and novel deep learning models) for automatically detecting different\n","types of sexist behaviours. Our results show that sexism is frequently found in many forms in social networks,\n","that it includes a wide range of behaviours, and that it is possible to detect them using deep learning\n","approaches. We discuss the performance of automatic classification methods to deal with different types\n","of sexism and the generalizability of our task to other subdomains, such as misogyny.\n","INDEX TERMS Sexism detection, social media, natural language processing, machine learning.\n","I. INTRODUCTION\n","The rapid development of web technologies and social networks has enabled the interaction between people from\n","different countries, cultures and ethnicities. Although the\n","advantages and positive effects of this global communication are obvious, the invisibility, anonymity and accessibility have made the expression of xenophobic, racist and\n","sexist discourses easy and unpunished. The so-called online\n","dis-inhibition effect [1] emboldens users to engage in behaviors they are unlikely to perform face-to-face. Moreover,\n","the quick spread of online information, especially in social\n","networks, has made these harassment behaviours extremely\n","dangerous, so that solutions are required to effectively reduce\n","the harm caused by hateful propaganda in cyberspace.\n","Hate speech can be defined as language that is used to\n","expresses hatred towards a targeted group or is intended\n","to be derogatory, to humiliate, or to insult the members of\n","the group [2]. Internet intermediaries like Facebook have\n","The associate editor coordinating the review of this manuscript and\n","approving it for publication was Wai-keung Fung .\n","recently announced increasing efforts to moderate and fight\n","against hateful and harmful speech [3], so that they can protect their users from harassment and hateful language. How\u0002ever, they recognized to be failing to detect some content of\n","this kind [4]. Other companies, like Twitter, are continuously\n","reviewing their policies to include additional types of abusive\n","behavior and creating new ways to eradicate hateful content\n","from their websites, that range from warnings to the deletion\n","of harmful tweets and even to the permanent suspension of\n","users.1 However, despite making a great effort and using\n","many human resources, they are facing many difficulties\n","when dealing with the huge amount of data generated by\n","users [5].\n","During the last years, the role of women within online\n","platforms has gained attention, unfortunately because of the\n","growing hatred and abuse against them. According to the\n","work of [6], women are about twice as likely as men to say\n","they have been harassed online as a result of their gender.\n","1https://help.twitter.com/en/rules-and-policies/hateful-conduct-policy\n","VOLUME 8, 2020 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ 219563\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","Recently, Amnesty International published a report2 where\n","they describe Twitter as a ‘‘toxic place’’ for women. According to this report, Twitter is promoting violence and hate\n","against or threaten people based on their gender. The report\n","also suggests that Twitter is failing to protect women against\n","harassment and it could have a negative impact on their\n","freedom of speech. Moreover, previous works have found a\n","relationship between verbal harassment to woman and action.\n","Fulper et al. [7], for instance, demonstrated the existence of\n","a correlation between the number of rapes and the amount\n","of misogynistic tweets per state in USA. Therefore, fighting\n","against online sexism is a social urgency.\n","The Oxford English Dictionary defines sexism as Prejudice, stereotyping or discrimination, typically against\n","women, on the basis of sex.\n","3 Similarly, the Real Academia\n","Española de la Lengua defines it as discrimination of people on the basis of sex.\n","4\n","In general, sexist behaviours\n","and discourses underestimate the role of women. Inequality\n","and discrimination against women that remains embedded\n","in society is increasingly being replicated online [8]. The\n","internet perpetuates and even naturalizes gender differences\n","and sexist attitudes [12]. Moreover, given that an important percentage of Internet users (especially social networks\n","users) are teenagers, the increasing sexism on the internet requires urgent study and social debate that leads to\n","actions. However, detecting online sexism may be difficult,\n","as it may be expressed in very different forms. Sexism may\n","sound ‘‘friendly’’: the statement ‘‘Women must be loved and\n","respected, always treat them like a fragile glass’’ may seem\n","positive, but is actually considering that women are weaker\n","than men. Sexism may sound ‘‘funny’’, as it is the case of\n","sexist jokes or humour (‘‘ You have to love women. . .just\n","that. . . You will never understand them.’’). Sexism may sound\n","‘‘offensive’’ and ‘‘hateful’’, as in ‘‘Humiliate, expose and\n","degrade yourself as the fucking bitch you are if you want\n","a real man to give you attention’’. However, even the most\n","subtle forms of sexism can be as pernicious as the most\n","violent ones and affect women in many facets of their lives\n","[10], [11], including domestic and parenting roles, career\n","opportunities, sexual image and life expectations, to name a\n","few.\n","Current research on sexism in online media is focused on\n","detecting misogyny or hatred towards women. The Oxford\n","English Dictionary defines misogyny as hatred or dislike of,\n","or prejudice against women. Sexism does not always imply\n","misogyny: when a man claims that he prefers his wife to stay\n","at home because this way she can attend his children better,\n","he is being sexist. When a man claims that wives should\n","only be allowed to stay at home, he is being misogynist.\n","Both attitudes are supporting a stereotype against a woman,\n","but the second expresses hostility and prejudice against her.\n","2https://www.amnesty.org/en/latest/research/2018/03/online-violenceagainst-women-chapter-1/\n","3https://www.oed.com/\n","4http://dle.rae.es/srv/search?m=30&w=sexismo\n","Therefore, works dealing with the detection of misogyny are\n","forgetting a wide spectrum of sexist attitudes and behaviours\n","that are, in fact, the most frequent and dangerous for the\n","society. Our aim is the detection of sexism in a broad\n","sense, from explicit misogyny to other subtle expressions that\n","involve implicit sexist behaviours. To the best of our knowledge, no previous work has addressed the detection of this\n","implicit, and not necessarily violent, sexism in social network\n","conversations.\n","In this paper, we aim to understand how sexist behaviours,\n","beliefs and attitudes are expressed in Twitter conversations.\n","We focus on tweets written in Spanish, although the method\n","employed and the conclusions extracted are directly applicable to other languages. We propose to identify sexism in\n","social networks using an automatic system based on machine\n","learning. First, we collect tweets automatically and compose\n","a new dataset, MeTwo. Then, a series of machine learning\n","algorithms are applied to classify the tweets into sexist or nonsexist. Finally, an exhaustive analysis is performed to study\n","the properties of our system. This is a first step towards the\n","more ambitious goal of creating novel mechanisms to detect\n","and alert from abusive and sexist behaviours against women\n","in social media.\n","Our results show that we can successfully detect different\n","types of sexism. We prove that misogyny and hatred towards\n","women are easier to detect than subtle or non-hateful sexism\n","since it is much less context dependent. However, we observe\n","that subtle sexism is expected to be more frequently found\n","in our corpus and includes itself a wide range of behaviours.\n","We discuss the performance of automatic classification methods to deal with all these types of sexism. Similarly, we show\n","that a classification system trained on our dataset is able to\n","generalize better than the same system trained on a dataset of\n","misogynistic expressions.\n","In summary, our work has the following contributions:\n","• A new task is proposed in the area of offensive language\n","detection that broaden the scope of modeling sexism\n","detection in social media. We consider sexist attitudes\n","that affect different facets of women and that may be\n","subtle or hostile.\n","• The construction and manual annotation of the first\n","Spanish corpus of sexist expressions in Twitter (the\n","MeTwo dataset) that may be employed by the research\n","community to advance the state of the art in the proposed\n","task.\n","• The development of machine learning methods to\n","automatically detect sexism in tweets, including the\n","comparison of traditional ML methods with novel\n","approaches based on neural networks and transfer learning. We achieve considerable results outperforming the\n","baselines proposed and discuss the implications and\n","generalization of our approach.\n","The rest of this paper is organized as follows: in section 2,\n","we discuss related works. In section 3, the annotated corpus is presented. In section 4, we describe the classification\n","system. Results and analysis are presented in section 5.\n","219564 VOLUME 8, 2020\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","Finally, the conclusions and future works are given in\n","section 6.\n","II. RELATED WORK\n","Substantial work has been devoted to the detection of hate\n","speech in recent years, including tasks such as racist or xenophobic content detection, but few works have faced sexism\n","detection and, in particular, they have dealt with sexism as the\n","detection of hate speech against women. Consequently, they\n","have worked with hostile and explicit sexism, overlooking\n","subtle or implicit expressions of sexism. However, some ideas\n","and techniques from hate speech detection may apply to our\n","problem. Therefore, in this section, we briefly review related\n","work in the hate speech field along with previous works on\n","sexism and misogyny detection.\n","A. HATE SPEECH DETECTION\n","The hate speech detection task consists in detecting hateful\n","content in online communities. With the spread of Internet\n","and the growth of online interactions, many users have the\n","risk of being harassed on social media, blogs or forums. This\n","particular form of harassment can have a negative impact\n","on their online experience and the community in general.\n","Sentences such as ‘‘this niggers are taking the jobs of locals’’\n","or ‘‘Every human being who is a #muslim should be killed.\n","End of story. #islam #IslamicState’’ targeting minority groups\n","are seen online daily.\n","In recent years, the Artificial Intelligence for Social Good\n","(AI4SG) movement has promoted the creation of applications\n","to protect minority groups on the Internet [16]. Some works\n","have dealt with the prevention of sexual harassment [17],\n","sexual discrimination detection [18], and cyberbully and\n","trolling [19]. More recent works have dealt with suicidal\n","ideation detection to address some real consequences of hate\n","on the Internet [20].\n","First works on hate speech detection were based on bagof-words (BOW) approaches [2], [14], [15]. In 2012, we find\n","one of the earlier researches using machine learning based\n","classifiers for detecting abusive language [21] as opposed to\n","the pattern-based methods [22]. Traditional machine learning\n","algorithms such as logistic regression [14], support vector\n","machines and decision trees [2] have been widely employed\n","to detect hate speech. Non-linguistic features like the gender\n","or ethnicity of the author can help improve hate speech classification but this information is often unavailable or unreliable\n","on social media [15]. There are also approaches that include\n","some forms of sentiment information as features. Hate is a\n","negative emotion, and thus it is fair to suppose that messages\n","expressive negative emotions are more probably expressing\n","hate than those expressing neutral o positive emotions. As a\n","result, sentiment analysis and polarity detection techniques\n","are usually applied to hate detection [13], [23].\n","Also inspired by the sentiment analysis and affective com\u0002puting works, the use of external lexical resources has been\n","applied to hate speech detection [24]. In [25], a lexicon of\n","hate verbs which condone or encourage acts of violence is\n","developed. Since lexicon-based classification depends\n","greatly on the availability of high quality external resources,\n","other works merge the benefits of the machine learning\n","and lexicon-based classification approaches to detect hate\n","speech [26].\n","During the last years, the application of neural models to\n","hate speech detection has gained attention. These models typ\u0002ically apply deep learning approaches such as Convolutional\n","Neural Networks (CNNs) and Long Short-Term Memory\n","Networks (LSTMs) [27]–[30], showing impressive results in\n","many tasks related to natural language processing [31]. In this\n","paper, we apply some of these methods to our problem along\n","with transfer learning techniques [32].\n","Due to the availability of resources, the majority of studies\n","on hate speech detection works on English texts. However,\n","the academic event SemEval 2019 (Task 5) aimed to detect\n","hate speech against immigrants and women in Spanish and\n","English messages extracted from Twitter [33] and promoted\n","research in Spanish. In this task, deep learning approaches\n","were proposed to detect misogyny and racism in texts in\n","Spanish [34]. Similarly, [37] aims to detect cyber hate speech\n","in Arabic tweets employing a wide range of traditional\n","machine learning techniques.\n","B. MISOGYNY DETECTION\n","‘‘Misogyny’’ and ‘‘sexism’’ are frequently considered inter\u0002changeable, though both terms have different nuances.\n","Currently, the definition of misogyny is under discussion\n","[35], [36]. However, the most widely accepted definition\n","of misogyny implies the expression of hostility and hatred\n","towards women. In contrast, sexism comprises any form of\n","oppression or prejudice against women and therefore may be\n","hostile (as in the case of misogyny) or subtle. Thus, sexism\n","includes misogyny but is not limited to it.\n","Current studies on the identification of sexism are related\n","to hate speech detection. One of the first datasets was devel\u0002oped to study sexism in conjunction with racism [14], [15] .\n","However, this dataset only comprises the expression of hate\n","or hostile sexism towards women, overlooking other kinds of\n","sexism. Sharifirad and Jacovi [38] presented a categorization\n","of sexism that included indirect, sexual, and physical sexism.\n","A more recent study by [39] seeks to categorize accounts\n","of sexism. Because the growing interest of hate detection\n","towards women, other tasks to protect women from hate on\n","the internet have emerged. For instance, sexist MEME detec\u0002tion [40] and classification of sexist advertisements [41].\n","We can find in the literature previous works that have\n","specifically faced the automatic detection of misogyny in text\n","[42]–[45] as well as some datasets annotated with misogynist\n","expressions [33]. ElSherief et al. [46] compiled Hate Lingo,\n","an English dataset that comprises hate speech tweets that\n","include hatred expressions towards people based on some\n","intrinsic characteristics of the person, including their gender,\n","class, ethnicity or religion. Similarly, Ousidhoum et al. [47]\n","create a multi-lingual corpus that included expressions of hate\n","towards women in English, French and Arabic. Similarly,\n","VOLUME 8, 2020 219565\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","El Ansari et al. [48] construct a dataset combining manual\n","and automatic annotation of Arabic texts addressing discrim\u0002ination and violence against women.\n","Recently, the IberEval competition focused on the auto\u0002matic identification of misogyny in Twitter [49]. Teams\n","were proposed to identify misogynist tweets both in Spanish\n","and English. The corpus created in this competition (AMI\n","dataset) was also used to build the dataset for SemEval\n","2019 Task 5 [33]. Approaches presented to the competi\u0002tion were mainly based on supervised machine learning on\n","different textual features (such as unigrams and bigrams,\n","sentiment-based information, or syntactic categories) or\n","user-based features (such as the number of retweets, follow\u0002ers, etc.) [50]–[52]. The use of lexical resources for extracting\n","signals (such as swear word count, sexist slurs presence)\n","showed excellent performance in the task [53]. Deep learning\n","methods, such as recurrent neural networks, are explored\n","in [54] along with word embedding features.\n","However, to the best of our knowledge, no previous work\n","has explicitly tackled subtle sexism in social networks, nor\n","has produced annotated datasets that enable the study and\n","detection of the broad spectrum of behaviors and expres\u0002sions that sexism encompasses. In this work, we develop the\n","MeTwo dataset, a corpus of sexist tweets in Spanish that aims\n","to help automatic systems to detect the broad spectrum of sex\u0002ist attitudes that occur in Twitter. The dataset is accompanied\n","by an exhaustive study and categorization of frequent sexist\n","expressions in social networks.\n","III. MeTwo: MACHISMO AND SEXISM TWITTER\n","IDENTIFICATION DATASET\n","In this section, the MeTwo dataset, a corpus for the detection\n","of sexist expressions and attitudes in Twitter, is presented.\n","The method to compile and annotate the corpus is described\n","and some data statistics are shown. As already mentioned,\n","although some datasets of misogyny and hate speech are\n","available [15], [33], [44], to the best of our knowledge,\n","MeTwo is the first corpus in Spanish designed to identify\n","sexism in a broad sense, from hostile to much more sub\u0002tle sexism. The MeTwo dataset is available for research at\n","Github.5\n","A. CORPUS COLLECTION\n","To bootstrap our dataset, we first collected a number of pop\u0002ular expressions and terms commonly used to underestimate\n","the role of women in our society, encourage the harassment\n","towards them or limit their freedom of speech. Our main\n","source for such expressions was the Twitter account of the\n","Spanish journalist Ana Isabel Bernal-Triviño,6 which col\u0002lects phrases and expressions that women (Twitter users)\n","have received on a day-to-day basis, and that have made\n","them feel belittled and undermined because of their genre.\n","We manually inspected them to select both expressions that\n","5https://github.com/franciscorodriguez92/MeTwo\n","6Ana Isabel Bernal-Triviño Twitter account: @anaisbernal\n","TABLE 1. Tweets collected per term.\n","may be clearly offensive, or even violent, and expressions\n","that are subtle or even normalized. Table 1 shows the terms\n","and expressions selected to build the MeTwo dataset. Initially,\n","a total of 29 Spanish terms and expressions were considered\n","as keywords to create the corpus.\n","Starting from these expressions, we used the Twitter API\n","to search for tweets containing all selected keywords. Data\n","was collected between July and December 2018, gathering\n","181792 tweets for terms listed in Table 1. The initial setup\n","of our crawler implies collecting 100 tweets for each term\n","daily, thus, ideally we would collect 2900 tweets per day.\n","Using this methodology for corpus construction, we ensure\n","that we obtain both sexist and non-sexist tweets for each\n","keyword expression. For example, even the expression ‘‘a\n","fregar’’ (‘‘go washing’’) is commonly used to under-valuate\n","women’s capacity to work, it also occurs in non-sexist tweets\n","and our dataset is expected to reflect this ambiguity.\n","We established two constraints to the data collection\n","process. On the one hand, we limited the collection of\n","tweets to 15000 per keyword expression. On the other hand,\n","we set a minimum threshold of 150 tweets per expression.\n","After collecting the information, we took a random sample\n","of 150 tweets per term. We verified that tweets had a differ\u0002ence of at least one day to avoid conversations and to ensure\n","data is spread over the six months. Table 1 shows the number\n","of tweets collected per term. We discarded 5 terms since they\n","do not reach 150 tweets. As mentioned above, we sample\n","the original dataset to build the final corpus composed by\n","3600 tweets.\n","219566 VOLUME 8, 2020\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","TABLE 2. Terms selected to build MeTwo together with examples of sexist and non-sexist tweets extracted from the crawled tweets.\n","TABLE 3. Terms selected to build MeTwo together with examples of sexist and non-sexist tweets extracted from the crawled tweets (English translation).\n","After this, we manually examined the dataset in order\n","to understand the different ways that sexism is expressed\n","and the different facets of women that are most frequently\n","undermined or criticised in online communications via social\n","networks such as Twitter. Table 2 (which is translated to\n","English in Table 3) shows the sexist terms and expressions\n","grouped by their category and semantic meaning, along with\n","examples for both sexist and non-sexist tweets that include\n","such terms. It is important to note that this grouping of tweets\n","is not meant to be an exhaustive categorization of sexist\n","expressions and is only based on the empirical observation\n","of the dataset.\n","Group 1 gathers terms and expressions related to ideolog\u0002ical sexism. Terms in this group try to underestimate femi\u0002nism and the struggle of women for equality. For instance,\n","the term ‘‘feminazi’’ is widely used on social media to attach\n","VOLUME 8, 2020 219567\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","negative connotations to feminism by comparing it to nazism.\n","An example of ‘‘feminazi’’ in a sexist context can be shown in\n","the tweet ‘‘Uy habló de inventos la feminazi’’ (‘‘Oops talking\n","about lies the feminazi’’). Similarly, the tweet ‘‘Las feministas\n","de esta época forman círculos cerrados, levantan banderas\n","caprichosas y difíciles de ondear, se defienden entre sí, no el\n","género de manera conjunta, y no ven más allá de su núcleo o\n","colectivo.’’ (‘‘The feminists of this time form closed groups,\n","raise flags that are difficult to wave, defend their organization\n","but not the gender jointly and do not see beyond their collec\u0002tive.’’) from table 2 is underestimating feminism. Because of\n","the problem of word ambiguity, we can also find this term in\n","non-sexist contexts like in the sentence ‘‘?‘No te convencen\n","mis argumentos? Intentemos debatir. ?‘Usas ‘‘feminazi’’? Te\n","quedas solo’’ (‘‘Don’t my arguments convince you? Let’s try\n","to debate. Do you use ‘‘feminazi’’? You stay alone’’).\n","Group 2 collects terms associated with role stereotyping,\n","in particular, those suggesting that women are meant to do\n","the housework and parenting. The tweet ‘‘@user Nos pone\n","a fregar rápido, como tiene que hacer una mujer de su casa\n","digna de su hijo.’’ (‘‘@user makes us wash immediately, as a\n","woman in her house worthy of her child’’) is an example of\n","sexist expression in this group.\n","Terms in group 3 underestimate the ability of women\n","to carry out some tasks (intellectual incapacity and infe\u0002riority). The sentence ‘‘Mujer al volante, tenga cuidado!’’\n","(Woman driving, be careful!) underestimates women’s ability\n","to drive.\n","Expressions in group 4 aim to sexualize and objectify\n","women. This group collects terms that suggest women have\n","sex in exchange for money or favors, or that consider that\n","women must be sexually active and willing to satisfy the\n","sexual needs of men. The sentences ‘‘No le presten aten\u0002cion. como yo hago a cualquier otra zorra’’ (Do not pay\n","attention. as I do to any other slut) and ‘‘Y CON ESA\n","CARITA DE MOJIGATA QUE TIENE. . . :). . . SON LAS PEO\u0002RES. . . ’’ (AND WITH THAT PURITAN FACE THAT SHE\n","HAS. . . :). . . THEY ARE THE WORST. . .) use terms ‘‘zorra’’\n","(slut or bitch) and ‘‘mojigata’’ (puritan) in a sexist context.\n","Group 5 captures terms expressing patriarchy\n","behaviours and male dominance. These terms are used to\n","suggest that men and women play different roles in soci\u0002ety and that men deserve greater privileges than women.\n","For instance, the sentence ‘‘Por eso es que las mujeres no\n","deberían tener derecho al voto’’ (‘‘That’s why women should\n","not vote’’) suggests that only men should be allowed to decide\n","at the polls.\n","Group 6 gathers terms that are frequently used to express\n","hate and violence against women. It includes tweets that\n","explicitly express hatred towards them. It is also important to\n","clarify that the term ‘‘niñata’’ (little girl) is used to indicate\n","that a woman is immature so it does not necessarily have\n","sexist connotations. Figure 1 shows how most of the tweets\n","containing this term are annotated as non-sexist. The sentence\n","‘‘dios mio como odio a las mujeres, una mas embrollera que\n","la otra’’ (My God, how I hate women, one more confusing\n","than the other) would be an example of this category. Accord\u0002ing to the definition of misogyny as hatred or prejudice\n","against women, this group would be the closest to it.\n","Finally, group 7 contains terms used to suggest that women\n","should take care of their physical appearance. It is important\n","to say that ‘‘marimacho’’ can be also used as a homophobic\n","term since it suggests a woman has masculine features but it\n","is not sexist per se. However, it can be also used in a sexist\n","context like in sentence ‘‘@user la dictadura de las feas,\n","sobre las bonitas. Aún no conozco a una feminazi, mina o\n","que no sea marimacho. Porque será?’’ (the dictatorship of the\n","ugly, over the beautiful. I still don’t know a feminazi who isn’t\n","a marimacho. Why is that?). On the other hand, the sentence\n","‘‘me han llamado marimacho toda mi vida, pero eh ahora\n","como mola tu rollo tia xd’’ (I’ve been called marimacho all\n","my life, but now: hey your style is so cool lol) represents a\n","non-sexist example.\n","B. ANNOTATION AND AGREEMENT\n","We propose the following labels to identify sexist expressions\n","and behaviours in Twitter:\n","• SEXIST: tweets that underestimate women as a result\n","of their gender, independently of the facet of women\n","that is criticised, and independently of the intentionality\n","and violence. Example: ‘‘@user Lo irónico es que lo\n","dice una mujer, que naturalmente debería callarse y\n","dedicarse a la cocina, limpiar y criar hijos’’ (‘‘@user\n","The irony is that it is being said by a woman, which\n","naturally should shut up and devote herself to cooking,\n","cleaning and raising children’’).\n","• NON-SEXIST: tweets without sexist connotations.\n","In this category, we could find xenophobic or offen\u0002sive tweets but that do not understimate women for\n","the reason of their gender. For instance: ‘‘@user\n","@user POR CIERTO, EN TU FOTO DE PERFIL SE\n","PUEDE OBSERVAR QUE ERES BASTANTE VARONIL,\n","ASÍ QUE SI NO ERES MARIMACHO, EMPIEZA A\n","SERLO’’ (‘‘by the way, in your profile picture you can\n","see that you are quite manly, so if you are not a marima\u0002cho, yo should start to be’’).\n","• DOUBTFUL: tweets that could be sexist depending on\n","the context, which can not be inferred from the text in\n","the tweet. In this category we find tweets that would be\n","sexist if they were specifically targeted to women, such\n","as, for example: ‘‘@user @user Más vale que se marche\n","a fregar!’’ (‘‘@user @user You better go washing!’’).\n","MeTwo was labeled based on a majority vote by three\n","annotators. In case of total disagreement, a fourth annotator\n","decided the final label. Of the 3600 tweets, the fourth anno\u0002tator was only required in 20 tweets. Given the subjectivity\n","and difficulty of the task, we developed an annotation guide\n","in which we provided a clear explanation of each label along\n","with a number of examples.\n","During the annotation process, some difficulties were\n","found due to language phenomena such as irony or\n","219568 VOLUME 8, 2020\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","TABLE 4. Agreement between annotators (average of kappa coefficient).\n","ambiguity. For instance, the sentence ‘‘Mucho feminismo\n","pero a la primera de cambio. . . .’’(‘‘Much feminism but at the\n","first opportunity. . . ..’’) could be using irony making harder\n","to detect a sexist attitude. A good example of the impor\u0002tance of ambiguity can be shown in the sentence ‘‘@user\n","La zorra guardando las gallinas. !\n","Que se encargue Rosell\n","!! Bueno.. . , cuando salga de la cárcel. Cinismo en grado\n","máximo.’’ (‘‘@user The [fox/slut] keeping the chickens. !! Let\n","Rosell take care Well . . .when he leaves the jail. Cynicism in\n","maximum degree.’’). The word ‘‘zorra’’ in Spanish could be\n","refered to ‘‘slut’’ or to ‘‘fox’’ so it is unclear if it is employed\n","in a sexist context.\n","Another important problem found is related to tweets\n","which cite sexist content [56]. One could argue than the\n","tweets are not sexist per se, but they tell about sexist\n","behaviours. A good example of this problem can be shown\n","in the sentence ‘‘Pareces una puta con ese pantalón. -Mi her\u0002mano de 13 cuando me vió con un pantalón de cuero’’(‘‘You\n","look like a whore with those pants. -My brother of 13 when\n","he saw me wearing leather pants’’). In this work, all tweets\n","containing sexist cites have been considered as sexist.\n","To assess the reliability of the annotation process, we eval\u0002uate the inter-annotator agreement. To measure this, we opted\n","for the Cohen’s kappa coefficient [55]. A poor value on\n","this measure could indicate some problem in the annotation\n","process. On the one hand, it may suggest that the task is too\n","difficult or subjective, even for humans. On the other hand,\n","it may indicate that annotators are not prepared enough to\n","carry out the task. Final inter-annotator agreement results are\n","shown in Table 4. We achieved a value of 0.75 for kappa coef\u0002ficient. Kappa values greater than 0.6 are usually consider as\n","substantial agreement and adequate for this type of task [57].\n","Moreover, in Table 5, the percentage of agreement for the\n","three annotators by label is depicted. The ‘‘DOUBTFUL’’\n","label seems to be the most difficult to detect even for humans.\n","This may be due to the fact that, in some cases, the existence\n","of sexist context is subjective. For instance, the sentence\n","‘‘Profesiones preferidas de las feministas: Psicóloga, crítica\n","cultural, profesora universitaria, diputada.’’(‘‘Preferred pro\u0002fessions of feminists: Psychologist, cultural critic, university\n","professor, congresswoman.’’) has been considered ‘‘DOUBT\u0002FUL’’ by two annotators and ‘‘SEXIST’’ by the other one.\n","On the contrary, annotators seem mostly to agree on the\n","‘‘NON-SEXIST’’ and ‘‘SEXIST’’ labels.\n","The distribution of labels in the dataset is showed\n","in Table 6. As it can be observed, there is an important bias\n","TABLE 5. Total agreement by label.\n","TABLE 6. Distribution of labels in the dataset.\n","FIGURE 1. Terms distribution by category.\n","towards the ‘‘NON-SEXIST’’ label, due to the nature of the\n","problem.\n","Finally, Figure 1 shows the distribution of labels by term.\n","Note that, as previously mentioned, ‘‘niñata’’ (‘‘little girl’’)\n","and ‘‘marimacho’’ are considered sexist only in very specific\n","contexts, so that tweets containing such terms are usually\n","labeled as ‘‘NON-SEXIST’’. In contrast, we can see that\n","terms such as ‘‘feminazi’’ or ‘‘nenaza’’ are mostly used in\n","sexist contexts. Besides, there are terms, such as ‘‘zorra’’\n","(slut or bitch) o ‘‘a fregar’’ (‘‘go washing’’), for which the\n","percentage of ‘‘DOUBTFUL’’ tweets is very high, given that\n","these are polysemous words whose meaning strongly depends\n","on the context.\n","VOLUME 8, 2020 219569\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","FIGURE 2. Classification system architecture.\n","IV. AUTOMATIC DETECTION OF SEXISM IN TWITTER\n","We propose to identify sexist speech on social media using\n","a supervised classification system. The overall experiment\n","plan which describes the three main approaches to solve the\n","classification task is depicted in Figure 2.\n","In the first step, a preprocessing is carried out so that\n","the text is cleaned and all relevant linguistic, user and\n","network-based features are collected. To this end, different\n","transformations to features are applied to feed the ML algo\u0002rithms used. Next, features are combined differently depend\u0002ing on the classification model. Finally, the classification\n","module uses the information gathered in the previous steps\n","to identify sexist signals in text. We compare both tradi\u0002tional methods using tf-idf features and deep learning-based\n","methods using word embeddings. The following subsections\n","describe the classification module in detail. The code for all\n","methods has been made available on Github.7\n","A. FEATURE EXTRACTION\n","In order to gather useful information for the classification\n","algorithm, a preprocessing step is accomplished. Besides tex\u0002tual attributes, we experiment with other additional features\n","in order to enrich the information available in the classi\u0002fication step. More specifically, features considered can be\n","grouped into user-, network-, or text-based.\n","1) USER AND NETWORK-BASED FEATURES\n","Regarding user-based features, we use the following data that\n","is directly extracted from the user’s Twitter profile: followers\n","count, friends count, number of lists registered, number of\n","tweets posted, number of favorites registered, device used to\n","post and presence of verification. Besides, we employ some\n","features related to the network and how it interacts with the\n","7https://github.com/franciscorodriguez92/code-sexism-detection-spanish\n","tweet. In particular, we use favourite count, retweet count,\n","presence of hashtags, presence of URLs, presence of images\n","or videos and presence of mentions.\n","2) TEXT-BASED FEATURES\n","Features extracted from the text of the tweets are, a priori,\n","the most relevant for our classification system. In this group\n","of features, we use two different ones: the text and the length\n","of the tweet. Before extracting the textual signals, we apply\n","the following preproceessing to the texts:\n","• Replacing emojis by a description.\n","• Replacing URLs by the keyword ‘‘twurl’’.\n","• Replacing user mentions by the keyword ‘‘twuser’’.\n","• Removing Spanish accents.\n","• Removing punctuation marks.\n","• Converting hashtags containing capital letters. For\n","instance, we convert ‘‘#HappyBirthday’’ to ‘‘happy\n","birthday’’.\n","• Replacing the rest of the hashtags by the keyword\n","‘‘twhashtag’’.\n","• Converting all letters to lowercase.\n","• Replacing exclamation marks by the keyword ‘‘twexcla\u0002mation’’.\n","• Replacing question marks by the keyword ‘‘twinterroga\u0002tion’’.\n","• Tokenizing the text of the tweet, using the NLTK api.8\n","• Removing stop words\n","• Normalizing and replacing slang, using a Spanish lexi\u0002con developed in [58].\n","• Stemming, using the Porter Stemmer [59].\n","Once all the preprocess has been applied to the text,\n","the next step aims to build the features that will feed the\n","8https://www.nltk.org/api/nltk.tokenize.html#module\u0002nltk.tokenize.casual\n","219570 VOLUME 8, 2020\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","classifiers. We divide the text features in two categories:\n","lexical (tf-idf features) and semantic (word embeddings).\n","On the one hand, traditional classification systems use\n","tf-idf vectors, which are built from the tweets unigrams.\n","We explore the use of bigrams and trigrams without any\n","improvement. Tf-idf features are created using terms whose\n","document frequency is, at least, 1%. On the other hand, deep\n","learning methods use a word embedding approach to detect\n","semantic and syntactic words relations. In this paper, all the\n","pre-trained embeddings are built using the word2vec algo\u0002rithm [60]. This method allows us to assign a static numeric\n","vector to each token.\n","We use three different pre-trained word embedding\n","datasets. Firstly, we employ an embedding resource trained\n","on the Spanish Billion Word Corpus (SBWCE) [61]. This\n","dataset consists of more than one million word embeddings\n","of dimension 300. Secondly, we use a pre-trained resource\n","trained on tweets [62] using a vector length of 200 dimen\u0002sions (WESB). Finally, we use a pre-trained word embedding\n","resource trained on the Spanish CoNLL17 corpus [63] com\u0002posed of 300-dimensional vectors (CoNLL17).\n","B. CLASSICAL CLASSIFICATION METHODS\n","A number of classical machine learning techniques can be\n","used for this task. We opted for Logistic Regression (LR),\n","Support Vector Machine (SVM) and Random Forest (RF)\n","since they are widely used for this type of task [14], [50],\n","[64], [65].\n","As far as the feature extraction is concerned, user\n","and network-based features are used along with TF-IDF\n","attributes. For every classifier, default hyper-parameters are\n","employed so that they are not tuned using a sample of MeTwo.\n","We have explored hyper-parameters tuning using a sample of\n","data without success.\n","C. BIDIRECTIONAL LONG SHORT-TERM MEMORY\n","(BI-LSTM)\n","Approaches based on neural networks have been successfully\n","used for Natural Language Processing tasks [28], [54]. In this\n","paper, we compare some deep neural network approaches\n","to the classical ones. In particular, we experiment with\n","deep recurrent neural networks such as Bidirectional Long\n","Short-Term Memory (Bi-LSTM) [66]. We use Bi-LSTMs to\n","capture long range dependencies in tweets, which may not be\n","captured by classical classification algorithms.\n","Our Bi-LSTM model architecture is depicted in Figure 3.\n","The first layer of the network performs word embedding.\n","We experiment four different configurations for this layer.\n","First, we experiment with an embedding layer that is trained\n","along with all the network. For all other experiments, we use\n","the pre-trained embeddings described in subsection IV-A2.\n","The next layer is composed by a Bi-LSTM module\n","with 200 units (LSTM cells) as input and 50-dimensional\n","vectors as output. Then, we apply max pooling opera\u0002tion since we get all hidden states in previous Bi-LSTM\n","layer. Next, a dropout layer (0.1 dropout rate) is applied\n","FIGURE 3. Bi-LSTM architecture.\n","to avoid over-fitting. After that, we concatenate user and\n","network-based features to the output of previous layer and\n","add a fully-connected layer (dense layer).\n","Finally, we add a dropout layer (0.1 dropout rate) and a\n","fully-connected output layer with one neuron per predicted\n","class (three neurons in total), and a sigmoid activation to\n","normalize output values. The Adam optimizer [67] is used\n","along with binary cross entropy as loss function.\n","D. BIDIRECTIONAL ENCODER REPRESENTATIONS FROM\n","TRANSFORMERS (BERT)\n","In the previous section, one of the most frequently used\n","context-independent neural embedding is applied. Here,\n","we apply a context-dependent and transformer-based lan\u0002guage model called BERT [31]. In particular, we use\n","BERT-Base Multilingual Cased9 which provides sentence\n","representations for 104 languages. Since its publication,\n","many positive experimental results have been published in\n","different tasks [68], [69]. To perform the sexism detection\n","task, we fine-tune the pre-trained mBERT-Base parameters\n","adding a fully-connected layer on top of mBERT to mini\u0002mize loss function in our particular task. In our experiments,\n","we trained our classifier with a batch size of 16 for 25 epochs.\n","The dropout probability is set to 0.1 for all layers. The Adam\n","optimizer is used with a learning rate of 2−5\n","and a weight\n","decay of 0.01. As an input, we tokenized each tweet using\n","the BERT tokenizer.\n","V. RESULTS AND ANALYSIS\n","In this section, we analyze and discuss the results obtained in\n","all different experiments. We also include the details of our\n","evaluation methods and error analysis.\n","A. EXPERIMENTAL SETUP\n","For our experiments, we use classical and neural network\n","machine learning libraries in Python. For the implementa\u0002tion of Bi-LSTM, Keras10 was used. On the other hand,\n","we used pytorch [70] for the implementation of mBERT.\n","In particular, the transformers library from huggingface was\n","employed [71]. Finally, the scikit-learn11 library was used to\n","implement traditional classification systems.\n","9https://github.com/google-research/bert/blob/master/multilingual.md\n","10https://keras.io/\n","11https://scikit-learn.org/\n","VOLUME 8, 2020 219571\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","TABLE 7. Results for sexism detection for proposed methods.\n","B. SEXISM DETECTION RESULTS\n","Here, we report the performance of our proposed approaches\n","in comparison with the baselines. Two baselines have been\n","proposed: the first one is based on tf-idf features along with\n","the LR classifier; and the second one labels each record based\n","on the majority class.\n","The performance evaluation of all classifiers followed\n","a 10-fold cross-validation. The effectiveness is measured\n","using four different metrics: accuracy, precision, recall and\n","F1-score. Table 7 summarized the results obtained for each\n","classification method.\n","According to Table 7, mBERT with text features and\n","Bi-LSTM with WESB embeddings seem to perform the best.\n","Intuitively, this makes sense since BERT yields excellent\n","results in many tasks related to NLP [31] and is able to gather\n","information containing syntactical and contextual features.\n","On the other hand, pre-trained embeddings from WESB were\n","learned using tweets, which could be more appropriate to\n","represent tweets from MeTwo.\n","All methods outperform our baselines in all metrics.\n","As show in Table 7, all classical learning models achieve\n","comparable results with the exception of random for\u0002est, whose high value in precision is due to the bias\n","towards ‘‘NON-SEXIST’’ tweets in the class distribution\n","(see Table 6). Traditional methods also perform similarly\n","to Bi-LSTM without pre-trained embeddings. By contrast,\n","combining Bi-LSTM with pre-trained word embeddings\n","improves the performance of the method up to 3% in\n","F1-score. Similarly, all versions of mBERT outperform tra\u0002ditional methods.\n","Regarding neural networks methods, mBERT and\n","Bi-LSTM with pre-trained word embeddings achieve com\u0002parable results. It is important to state that adding user and\n","network-based features does not lead to any improvement\n","for mBERT. This could be due to the fact that we are just\n","concatenating these extra features and adding a simple linear\n","layer on top of BERT to fine-tune the model [72]. A more\n","exhaustive study should be done to determine the influence\n","of extra features and how to combine them effectively when\n","using BERT.\n","C. ERROR ANALYSIS\n","Although we achieve interesting results and improvements\n","with respect to the baselines, all models are still making\n","TABLE 8. Confusion matrix for the mBERT classifier.\n","TABLE 9. Accuracy by group and term.\n","some mistakes. To understand better the source of the failures,\n","we have performed a deep analysis on model errors. In par\u0002ticular, we further investigate results of the mBERT model.\n","Table 8 shows the confusion matrix for mBERT when only\n","textual features are used. Note that ‘‘NON-SEXIST’’ tweets\n","are easier to classify than ‘‘DOUBTFUL’’ and ‘‘SEXIST’’.\n","‘‘NON-SEXIST’’ tweets are correctly classified with 85% of\n","accuracy. For ‘‘DOUBTFUL’’ class, almost 59% of tweets are\n","misclassified. Intuitively, this makes sense since ‘‘DOUBT\u0002FUL’’ is the minority class and our model does not have many\n","instances of this type during fine-tuning process. However,\n","given that our ultimate goal is to detect sexism, the mistakes\n","made for ‘‘SEXIST’’ class are critical. For this category,\n","a 65% of accuracy is achieved.\n","We have observed that the performance could depend on\n","the number of instances available for each class. There\u0002fore, it seems that increasing the number of instances for\n","‘‘SEXIST’’ class would improve its detection. It is worth\n","remembering that our work does not make use of any exter\u0002nal resource of sexist vocabulary. As mentioned, previous\n","works have demonstrated the benefit of using sexist lexicon.\n","Detecting sexist words and including them in the model could\n","help to reduce the misclassification of ‘‘SEXIST’’ tweets and\n","will be investigated in future work.\n","To further investigate errors when detecting ‘‘SEXIST’’\n","tweets, we analyze the performance for each seed term.\n","Table 9 shows accuracy by group of sexist terms and by\n","term. Groups 6 and 7 achieve the highest accuracy. On the\n","one hand, group 6 is composed by terms expressing hate and\n","219572 VOLUME 8, 2020\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","TABLE 10. Examples labeled by the model.\n","misogyny thus they were expected to be easier to detect, since\n","this type of hateful messages make use of a violent vocabulary\n","that is not usually employed in ‘‘NON-SEXIST’’ tweets. On\n","the other hand, group 7 achieves good performance because\n","of the unbalanced distribution of terms which it gathers\n","(Figure 1). In contrast, group 5, which represents the expres\u0002sion of male dominance, presents the second worst perfor\u0002mance. This may be due to the fact that sexism in this group\n","is more subtle and the sexist ideas are expressed implicitly,\n","using expressions and words that are highly dependent on\n","the context. The poor performance in group 4 is due to the\n","balanced distributions in its terms. The existence of many\n","‘‘DOUBTFUL’’ tweets makes more difficult the task since\n","the classifier performs poorly when detecting this class.\n","Regarding the accuracy by term, ‘‘niñata’’ and ‘‘marima\u0002cho’’ achieve the highest accuracy. This is because such terms\n","are highly biased to the ‘‘NON-SEXIST’’ label (Figure 1).\n","The amount of information should be increased so that we\n","have more diversity of labels for such terms. In contrast,\n","the expression ‘‘lagartona’’ has the worst performance. Most\n","tweets containing this term express sexist behaviours which\n","are not radical or explicit. Some of them gather subtle sexism\n","which is more difficult to detect.\n","After this quantitative error analysis, a manual inspection\n","has been carried out to better understand the problems of our\n","classification system. Table 10 gathers some of the examples\n","examined. In tweets 1 and 2 our classifier is not able to detect\n","sexism, the reasons seem to be the tweet length and the lack of\n","explicit sexist slung. There is a subset of tweets in which our\n","classifier tends to fail because the short length of the text and\n","the absence of terms highly used in sexist contexts. In fact,\n","we have observed that misclassified tweets were, on average,\n","5 characters shorter than the average in the MeTwo dataset.\n","Again, some cases containing implicit sexism such as\n","tweets 3, 4 and 5 are not detected by our classifier, the reasons\n","being the use of irony and the lack of explicit sexist vocabu\u0002lary [73]. Regarding tweet 4, note that the expression ‘‘a las\n","mujeres hay’’ is biased towards the ‘‘NON-SEXIST’’ label\n","(Figure 1). Moreover, the tweet contains the term ‘‘bonito’’\n","(‘‘beautiful’’) which is not typically employed in sexist con\u0002texts. It is also important to note that our strategy to construct\n","TABLE 11. Generalization experiment.\n","the MeTwo dataset is keyword-based, which can introduce\n","natural biases towards certain sexist terms. Bias mitigation\n","techniques will be investigated in future works [74].\n","D. SEXISM DETECTION VS. AUTOMATIC MISOGYNY\n","DETECTION (AMI)\n","At this point, we wonder how well a model trained on our\n","corpus generalizes to other datasets from a subdomain of\n","sexism, such as misogyny. We have hypothesized that sexism\n","includes misogyny, hence MeTwo should be able to capture\n","some misogynistic attitudes and behaviours. To estimate this,\n","we train two models on MeTwo and evaluate in the AMI\n","dataset used for the IberEval competition, and vice versa.\n","The AMI dataset used for this experiment (training set) is\n","composed by 3307 tweets and considers only two classes:\n","‘‘misogynous’’ and ‘‘not misogynous’’. Therefore, to make\n","the comparison, we remove all tweets from ‘‘DOUBT\u0002FUL’’ class in MeTwo and use the ‘‘SEXIST’’ and ‘‘NON\u0002SEXIST’’ label to perform this experiment (3333 tweets).\n","We performed two different experiments with SVM and\n","mBERT in order to compare traditional with neural networks\n","based methods.\n","Table 11 shows the results of this experiment. We report\n","precision, recall and F1 for every class, and also a macro\n","average for all classes. We do not report accuracy since both\n","datasets are not fully balanced and would not be useful for\n","comparison. It can be observed that, performance training on\n","MeTwo is higher in all macro average metrics, hence evidenc\u0002ing that a model trained on MeTwo is able to generalize better\n","to AMI than vice versa. More noticeably, for the ‘‘SEXIST’’\n","class, MeTwo outperforms AMI for both classifiers.\n","These results show that MeTwo gathers sexist attitudes in\n","a broad sense, from misogyny to other types of sexism. Thus,\n","since MeTwo contains misogyny, the model trained on it is\n","able to correctly classify some of the information present in\n","AMI. In contrast, since AMI just contains tweets expressing\n","misogyny or hatred towards women, the model works worse\n","when evaluating on MeTwo, a dataset of broad sexism.\n","Additionally, we perform a last experiment using the\n","MeTwo corpus as training and only the test set of AMI for\n","evaluating the performance, so that we can compare our\n","results to the ones obtained during the AMI competition.\n","VOLUME 8, 2020 219573\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","TABLE 12. Generalization experiment on AMI test set.\n","Table 12 shows the results of this experiment as well as the\n","best and worst team, and baseline in the AMI competition.\n","Since the task organizers only provide the accuracy score as\n","the competition baseline, we will use this metric for compar\u0002ison. In terms of accuracy, our best system would rank 23 out\n","of 25 teams with an accuracy of 0.65 [49].\n","It must be noted that, since they share data collection\n","approaches, there is a strong relationship between both test\n","and training sets unigrams in AMI. Some of the most frequent\n","unigrams for misogynistic tweets in both sets are ‘‘puta’’\n","(bitch), ‘‘perra’’ (bitch/slut) or ‘‘callate’’ (shut up). However,\n","the most frequent unigrams for sexist tweets in MeTwo are\n","‘‘mujer’’ (woman), ‘‘mujeres’’ (women), ‘‘feminismo’’ (fem\u0002inism). Therefore, it was expected that a classifier trained on\n","the training set of AMI will outperform the one trained on\n","the MeTwo training set when evaluating on the test set of\n","AMI. This is due to the fact that, even if both datasets are\n","topic-related, the performance of this experiment is heavily\n","influenced by the data collection approaches. In addition to\n","this, we observe that the best results for AMI competition\n","were achieved using hate external lexicons. It suggests that\n","the use of hate slurs (less important in MeTwo) is a clear\n","signal of misogynistic content.\n","Nonetheless, even if we use for training a dataset that was\n","collected differently and for a different purpose than the one\n","used for testing, we still rank better than other participants\n","to the AMI challenge. It indicates that MeTwo is not just\n","composed of subtle and non-hateful tweets, but it also gathers\n","some misogynistic messages and can predict some of the\n","AMI tweets correctly.\n","VI. CONCLUSION AND FUTURE WORK\n","In this paper, we perform an exhaustive analysis to understand\n","how sexist attitudes and behaviours are expressed in social\n","networks conversations. In particular, our aim is to detect\n","sexism in a broad sense in Twitter. To this end, we presented\n","an automatic system based on ML that allows us to compare\n","traditional and neural networks based methods. Regarding\n","feature extraction, we compared methods based on tradi\u0002tional tf-idf features to word embeddings approaches. The\n","experimental results showed that BERT outperforms the rest\n","of algorithms tested achieving an accuracy of 74% in the\n","detection of sexist expressions. On the other hand, MeTwo\n","was presented, the first Spanish corpus of sexism expressions\n","in Twitter. The corpus is intended to cover a broad spectrum\n","of sexist attitudes, from subtle and non-hateful sexism to\n","misogyny and radical sexism. Metwo comprises 3600 tweets\n","labeled as sexist or not based on a majority vote by three\n","annotators. To the best of our knowledge, this is the first\n","resource of this type for Spanish texts. We have also made a\n","preliminary attempt to group sexist expressions in categories\n","according to the different facets of women that are attacked.\n","Furthermore, an error analysis has been performed to under\u0002stand the limitations of our system, that are mainly due to\n","linguistic phenomena such as irony and word ambiguity as\n","well as to the lack of enough context and the size of the\n","dataset.\n","As future work, we plan to extend our system to detect\n","different types of sexism such as sexualization or role stereo\u0002typing (see Tables 2 and 3). To this aim, a new exhaustive\n","categorization of sexist expressions should be done. This\n","may help to examine how the different types of sexism are\n","expressed and how they spread through social networks.\n","Besides, we will incorporate a multi-lingual approach to\n","handle different languages at the same time. To this end,\n","a new corpus will be created to include more data sources\n","and languages. Finally, new signals, such as the use of sexism\n","slurs, will be explored.\n","REFERENCES\n","[1] M. F. Wright, B. D. Harper, and S. Wachs, ‘‘The associations\n","between cyberbullying and callous-unemotional traits among adolescents:\n","The moderating effect of online disinhibition,’’ J. Personality Individual\n","Differences, vol. 140, pp. 41–45, Apr. 2019.\n","[2] T. Davidson, D. Warmsley, M. Macy, and I. Weber, ‘‘Automated hate\n","speech detection and the problem of offensive language,’’ in Proc. ICWSM,\n","2017, pp. 1–4.\n","[3] D. Gershgorn and M. Murphy. (2017). Facebook is Hiring More People\n","to Moderate Content than Twitter has at Its Entire Company Quartz.\n","Accessed: Jun. 20, 2019. [Online]. Available: https://bit.ly/2ZbhsHu\n","[4] T. Vega, ‘‘Facebook says it failed to bar posts with hate speech,’’ The\n","New York Times, 2013. Accessed: Jun. 10, 2019. [Online]. Available:\n","https://nyti.ms/2VXy9Ex\n","[5] R. Meyer, ‘‘Twitter’s famous racist problem,’’ The Atlantic, 2016.\n","Accessed: Jul. 5, 2019. [Online]. Available: https://bit.ly/38EnFPw\n","[6] M. Duggan, ‘‘Online harassment 2017,’’ Internet Tech., Pew Res. Center,\n","Washington, DC, USA, Tech. Rep., Jul. 2017.\n","[7] R. Fulper, G. L. Ciampaglia, E. Ferrara, Y. Ahn, A. Flammini, F. Menczer,\n","B. Lewis, and K. Rowe, ‘‘Misogynistic language on Twitter and sexual\n","violence,’’ in Proc. ChASM, 2015, pp. 1–4.\n","[8] A. Dhrodia, ‘‘Social media and the silencing effect: Why misogyny online\n","is a human rights issue,’’ NewStatesman, 2017. Accessed: Sep. 25, 2020.\n","[Online]. Available: https://bit.ly/3n3ox68\n","[9] A. Karami, C. N. White, K. Ford, S. Swan, and M. Yildiz Spinel,\n","‘‘Unwanted advances in higher education:Uncovering sexual harassment\n","experiences in academia with text mining,’’ Inf. Process. Manage., vol. 57,\n","no. 2, Mar. 2020, Art. no. 102167.\n","[10] D. E. J. Austin and M. Jackson, ‘‘Benevolent and hostile sexism dif\u0002ferentially predicted by facets of right-wing authoritarianism and social\n","dominance orientation,’’ Personality Individual Differences, vol. 139,\n","pp. 34–38, Mar. 2019.\n","[11] M. Thelwall and E. Stuart, ‘‘She’s reddit: A source of statistically signifi\u0002cant gendered interest information?’’ Inf. Process. Manage., vol. 56, no. 4,\n","pp. 1543–1558, Jul. 2019.\n","[12] T. Donoso-Vázquez, Violencias de Génereo 2.0, 1st ed. Barcelona, Spain:\n","Kit-Book, 2014, pp. 13–27.\n","[13] H. Watanabe, M. Bouazizi, and T. Ohtsuki, ‘‘Hate speech on Twitter:\n","A pragmatic approach to collect hateful and offensive expressions and\n","perform hate speech detection,’’ IEEE Access, vol. 6, pp. 13825–13835,\n","Feb. 2018.\n","219574 VOLUME 8, 2020\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","[14] Z. Waseem, ‘‘Are you a racist or am i seeing things? Annotator influence\n","on hate speech detection on Twitter,’’ in Proc. 1st Workshop NLP Comput.\n","Social Sci., 2016, pp. 138–142.\n","[15] Z. Waseem and D. Hovy, ‘‘Hateful symbols or hateful people? Predictive\n","features for hate speech detection on Twitter,’’ in Proc. NAACL Student\n","Res. Workshop, 2016, pp. 88–93.\n","[16] Z. Ryan Shi, C. Wang, and F. Fang, ‘‘Artificial intelligence for\n","social good: A survey,’’ 2020, arXiv:2001.01818. [Online]. Available:\n","http://arxiv.org/abs/2001.01818\n","[17] A. Khatua, E. Cambria, and A. Khatua, ‘‘Sounds of silence break\u0002ers: Exploring sexual violence on Twitter,’’ in Proc. ASONAM, 2018,\n","pp. 397–400.\n","[18] A. Khatua, E. Cambria, K. Ghosh, N. Chaki, and A. Khatua, ‘‘Tweeting in\n","support of LGBT? A deep learning approach,’’ in Proc. ACM India Joint\n","Int. Conf. Data Sci. Manage. Data, 2019, pp. 342–345.\n","[19] E. Cambria, P. Chandra, and A. Hussain, ‘‘Do not feel the trolls,’’ in Proc.\n","SDoW Workshop 9th Int. Semantic Web Conf., 2010, pp. 1–12.\n","[20] S. Ji, S. Pan, X. Li, E. Cambria, G. Long, and Z. Huang, ‘‘Suicidal\n","ideation detection: A review of machine learning methods and applica\u0002tions,’’ IEEE Trans. Comput. Social Syst., early access, Sep. 17, 2020, doi:\n","10.1109/TCSS.2020.3021467.\n","[21] G. Xiang, B. Fan, L. Wang, J. Hong, and C. Rose, ‘‘Detecting offen\u0002sive tweets via topical feature discovery over a large scale Twitter cor\u0002pus,’’ in Proc. 21st ACM Int. Conf. Inf. Knowl. Manage. (CIKM), 2012,\n","pp. 1980–1984.\n","[22] P. Gianfortoni, D. Adamson, and C. Rose, ‘‘Modeling of stylistic variation\n","in social media with stretchy patterns,’’ in Proc. EMNLP, 2011, pp. 49–59.\n","[23] E. Cambria, ‘‘Affective computing and sentiment analysis,’’ IEEE Intell.\n","Syst., vol. 31, no. 2, pp. 102–107, Mar. 2016.\n","[24] F. Del Vigna, A. Cimino, F. Dell’Orletta, M. Petrocchi, and M. Tesconi,\n","‘‘Hate me, hate me not: Hate speech detection on facebook,’’ in Proc.\n","ITASEC, 2017, pp. 86–95.\n","[25] N. D. Gitari, Z. Zhang, H. Damien, and J. Long, ‘‘A lexicon-based approach\n","for hate speech detection,’’ Int. J. Multimedia Ubiquitous Eng., vol. 10,\n","no. 4, pp. 215–230, Apr. 2015.\n","[26] Y. Tang and N. Dalzell, ‘‘Classifying hate speech using a two-layer\n","model,’’ Statist. Public Policy, vol. 6, no. 1, pp. 80–86, Jan. 2019, doi:\n","10.1080/2330443X.2019.1660285.\n","[27] G. K. Pitsilis, H. Ramampiaro, and H. Langseth, ‘‘Detecting offensive lan\u0002guage in tweets using deep learning,’’ 2018, arXiv:1801.04433. [Online].\n","Available: http://arxiv.org/abs/1801.04433\n","[28] P. Badjatiya, S. Gupta, M. Gupta, and V. Varma, ‘‘Deep learning for hate\n","speech detection in tweets,’’ in Proc. ACM WWW, 2017, pp. 759–760.\n","[29] S. Zimmerman, U. Kruschwitz, and C. Fox, ‘‘Improving hate speech\n","detection with deep learning ensembles,’’ in Proc. LREC, 2018, pp. 1–8.\n","[30] J. H. Park and P. Fung, ‘‘One-step and two-step classification for abusive\n","language detection on Twitter,’’ in Proc. 1st Workshop Abusive Lang.\n","Online, 2017, pp. 41–45.\n","[31] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘BERT: Pre-training\n","of deep bidirectional transformers for language understanding,’’ in Proc.\n","NAACL, 2019, pp. 4171–4186.\n","[32] S. J. Pan and Q. Yang, ‘‘A survey on transfer learning,’’ IEEE Trans. Knowl.\n","Data Eng., vol. 22, no. 10, pp. 1345–1359, Oct. 2009.\n","[33] V. Basile, C. Bosco, E. Fersini, D. Nozza, V. Patti, F. M. R. Pardo,\n","P. Rosso, and M. Sanguinetti, ‘‘SemEval-2019 task 5: Multilingual detec\u0002tion of hate speech against immigrants and women in Twitter,’’ in Proc.\n","13th Int. Workshop Semantic Eval., 2019, pp. 54–63.\n","[34] G. H. Paetzold, M. Zampieri, and S. Malmasi, ‘‘UTFPR at SemEval-2019\n","task 5: Hate speech identification with recurrent neural networks,’’ in Proc.\n","13th Int. Workshop Semantic Eval., 2019, pp. 519–523.\n","[35] M. Konstantinovsky. (2019). What’s the Difference Between Misogyny\n","and Sexism howstuffworks? Accessed: Jul. 13, 2020. [Online]. Available:\n","https://people.howstuffworks.com/misogyny-and-sexism.htm\n","[36] K. Manne, Down Girl: The Logic of Misogyny. London, U.K.: Oxford\n","Univ. Press, 2018.\n","[37] I. Aljarah, M. Habib, N. Hijazi, H. Faris, R. Qaddoura, B. Hammo,\n","M. Abushariah, and M. Alfawareh, ‘‘Intelligent detection of hate speech\n","in arabic social network: A machine learning approach,’’ J. Inf. Sci.,\n","May 2020, doi: 10.1177/0165551520917651.\n","[38] S. Sharifirad and A. Jacovi, ‘‘Learning and understanding different cat\u0002egories of sexism using convolutional neural network’s filters,’’ in Proc.\n","ACL, 2019, pp. 21–23.\n","[39] P. Parikh, H. Abburi, P. Badjatiya, R. Krishnan, N. Chhaya, M. Gupta, and\n","V. Varma, ‘‘Multi-label categorization of accounts of sexism using a neural\n","framework,’’ in Proc. EMNLP-IJCNLP, 2019, pp. 1642–1652.\n","[40] E. Fersini, F. Gasparini, S. Corchs, S. O. Textual, ‘‘Detecting sexist MEME\n","on the Web: A study on textual and visual cues,’’ in Proc. ACIIW, 2019,\n","pp. 226–231.\n","[41] F. Gasparini, I. Erba, E. Fersini, and S. Corchs, ‘‘Multimodal classification\n","of sexist advertisements,’’ in Proc. 15th Int. Joint Conf. e-Bus. Telecom\u0002mun., 2018, pp. 565–572.\n","[42] J. Cardiff and E. Shushkevich, ‘‘Misogyny detection and classification in\n","English tweets:the experience of the ITT team,’’ in Proc. EVALITA, 2018,\n","p. 182.\n","[43] D. Nozza, C. Volpetti, and E. Fersini, ‘‘Unintended bias in misogyny\n","detection,’’ in Proc. IEEE/WIC/ACM Int. Conf. Web Intell., Oct. 2019,\n","pp. 149–155.\n","[44] M. Anzovino, E. Fersini, and P. Rosso, ‘‘Automatic identification and\n","classification of misogynistic language on Twitter,’’ in Proc. NLDB, 2018,\n","pp. 57–64.\n","[45] E. W. Pamungkas, V. Basile, and V. Patti, ‘‘Misogyny detection in Twitter:\n","A multilingual and cross-domain study,’’ Inf. Process. Manage., vol. 57,\n","no. 6, Nov. 2020, Art. no. 102360.\n","[46] M. ElSherief, ‘‘Hate lingo: A target-based linguistic analysis of hate speech\n","in social media,’’ in Proc. AAAI, 2018, pp. 1–10.\n","[47] N. Ousidhoum, Z. Lin, H. Zhang, Y. Song, and D.-Y. Yeung, ‘‘Multilingual\n","and multi-aspect hate speech analysis,’’ in Proc. EMNLP-IJCNLP, 2019,\n","pp. 4667–4676.\n","[48] O. El Ansari, Z. Jihad, and M. Hajar, ‘‘A dataset to support sexist\n","content detection in arabic text,’’ J. Image Signal Process., vol. 12119,\n","pp. 130–137, Sep. 2020.\n","[49] E. Fersini, P. Rosso, and M. Anzovino, ‘‘Overview of the task on auto\u0002matic misogyny identification at IberEval 2018,’’ in Proc. IberEval, 2018,\n","pp. 214–228.\n","[50] J. S. Canós, ‘‘Misogyny identification through SVM at IberEval 2018,’’ in\n","Proc. IberEval, 2018, pp. 229–233.\n","[51] V. Nina-Alcocer, ‘‘AMI at IberEval2018 automatic misogyny identification\n","in Spanish and English tweets,’’ in Proc. IberEval, 2018, pp. 274–279.\n","[52] S. Frenda and B. Ghanem, ‘‘Exploration of misogyny in Spanish and\n","English tweets,’’ in Proc. IberEval, 2018, pp. 260–267.\n","[53] E. W. Pamungkas, ‘‘Exploiting lexical knowledge for detecting misogyny\n","in English and Spanish tweets,’’ in Proc. IberEval, 2018, pp. 234–241.\n","[54] I. Goenaga, A. Atutxa, K. Gojenola, A. Casillas, A. D. de Ilarraza,\n","N. Ezeiza, M. Oronoz, A. Pérez, and O. Perez-de-Viñaspre ‘‘Automatic\n","misogyny identification using neural networks,’’ in Proc. IberEval, 2018,\n","pp. 249–254.\n","[55] J. Cohen, ‘‘A coefficient of agreement for nominal scales,’’ Educ. Psychol.\n","Meas., vol. 20, no. 1, pp. 37–46, Apr. 1960.\n","[56] P. Chiril, V. Moriceau, F. Benamara, A. Mari, G. Origgi, and\n","M. Coulomb-Gully, ‘‘An annotated corpus for sexism detection in French\n","tweets,’’ in Proc. ACL, 2020, pp. 1397–1403.\n","[57] M. L. McHugh, ‘‘Interrater reliability: The kappa statistic,’’ Biochemia\n","Medica, vol. 22, no. 3, pp. 276–282, 2012.\n","[58] H. Gómez-Adorno, ‘‘Compilación de un lexicón de redes sociales para\n","la identificación de perfiles de autor,’’ J. Res. Comput. Sci., vol. 115,\n","pp. 19–27, May 2016.\n","[59] M. F. Porter, ‘‘An algorithm for suffix stripping,’’ J. Program., vol. 14,\n","pp. 130–137, Jul. 1980.\n","[60] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean ‘‘Distributed\n","representations of words and phrases and their compositionality,’’ in Proc.\n","NIPS, 2013, pp. 3111–3119.\n","[61] C. Cardellino. (Aug. 2019). Spanish Billion Words Corpus and Embed\u0002dings. Accessed: Dec. 10, 2019. [Online]. Available: https://crscardellino.\n","github.io/SBWCE/\n","[62] J. Deriu. Leveraging Large Amounts of Weakly Supervised Data for Multi\u0002Language Sentiment Classification. Accessed: Nov. 14, 2019. [Online].\n","Available: https://www.spinningbytes.com/resources/wordembeddings/\n","[63] M. Fares, M. Fares, S. Oepen, and E. Velldal, ‘‘Word vectors, reuse, and\n","replicability: Towards a community repository of large-text resources,’’ in\n","Proc. NoDaLiDa/WS, 2017, pp. 271–276.\n","[64] H. Liu, F. Chiroma, and E. Haig, ‘‘Identification and classification of\n","misogynous tweets using multi-classifier fusion,’’ in Proc. IberEval, 2018,\n","pp. 268–273.\n","[65] E. Shushkevich and J. Cardiff, ‘‘Classifying misogynistic tweets using\n","a blended model: The AMI shared task in IBEREVAL 2018,’’ in Proc.\n","IberEval, 2018, pp. 255–259.\n","VOLUME 8, 2020 219575\n","F. Rodríguez-Sánchez et al.: Automatic Classification of Sexism in Social Networks\n","[66] M. Schuster and K. K. Paliwal, ‘‘Bidirectional recurrent neural networks,’’\n","IEEE Trans. Signal Process., vol. 45, no. 11, pp. 2673–2681, 1997.\n","[67] P. Kingma and J. Ba, ‘‘Adam: A method for stochastic optimization,’’ in\n","Proc. ICLR, 2015, pp. 1–15.\n","[68] Y. Wang, W. Che, J. Guo, Y. Liu, and T. Liu, ‘‘Cross-lingual BERT trans\u0002formation for zero-shot dependency parsing,’’ in Proc. EMNLP-IJCNLP,\n","2019, pp. 5725–5731.\n","[69] T. Pires, E. Schlinger, and D. Garrette, ‘‘How multilingual is multilingual\n","BERT?’’ in Proc. 57th Annu. Meeting Assoc. Comput. Linguistics, 2019,\n","pp. 4996–5001.\n","[70] A. Paszke et al., ‘‘PyTorch: An imperative style, high-performance deep\n","learning library,’’ in Proc. NIPS, 2019, pp. 8026–8037.\n","[71] T. Wolf et al., ‘‘HuggingFace’s transformers: State-of-the-art natu\u0002ral language processing,’’ 2019, arXiv:1910.03771. [Online]. Available:\n","http://arxiv.org/abs/1910.03771\n","[72] M. Mozafari, R. Farahbakhsh, and N. Crespi, ‘‘A BERT-based transfer\n","learning approach for hate speech detection in online social media,’’ in\n","Proc. COMPLEX Netw., 2019, pp. 928–940.\n","[73] M. A. Di Gangi, G. Lo Bosco, and G. Pilato, ‘‘Effectiveness of data\u0002driven induction of semantic spaces and traditional classifiers for sarcasm\n","detection,’’ Natural Lang. Eng., vol. 25, no. 2, pp. 257–285, Mar. 2019.\n","[74] M. Mozafari, R. Farahbakhsh, and N. Crespi, ‘‘Hate speech detection and\n","racial bias mitigation in social media based on BERT model,’’ PLoS ONE,\n","vol. 1, Aug. 2020, Art. no. e0237861.\n","FRANCISCO RODRÍGUEZ-SÁNCHEZ received\n","the B.Sc. and M.Sc. degrees in telecommunica\u0002tions engineering from the Technical University\n","of Cartagena, and the M.Sc. degree in natural lan\u0002guage processing (NLP) from UNED, where he is\n","currently pursuing the Ph.D. degree. His research\n","interests include algorithms and NLP techniques\n","to detect hate speech and sexism online.\n","JORGE CARRILLO-DE-ALBORNOZ received\n","the master’s degree in computer science research\n","and the Ph.D. degree in natural language process\u0002ing. He is currently a Teaching Assistant with\n","UNED. He has participated in several national and\n","EU funded research projects and published over\n","30 articles in important conferences and journals in\n","the area. His research interests are in discovering\n","and representing sentiments and emotions in text\n","and automatically monitoring social networks for\n","tracking and detecting sensible information about companies and brands.\n","LAURA PLAZA is currently an Associate Profes\u0002sor with UNED and a Researcher with IR & NLP\n","Group, UNED. She has authored or coauthored\n","in more than 40 international journals and con\u0002ferences. She has participated in different funded\n","projects and worked in several international com\u0002panies. Her research includes different fields of\n","natural language processing, including summa\u0002rization, word sense disambiguation, information\n","retrieval and sentiment analysis, with an emphasis\n","on semantic approaches in the biomedical domain.\n","219576 VOLUME 8, 2020 \"\"\""],"metadata":{"id":"BGc4UiFaqK0Y","executionInfo":{"status":"ok","timestamp":1707394933340,"user_tz":-330,"elapsed":909,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lq2UoaTuqxgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer"],"metadata":{"id":"M8xxeHofq4fy","executionInfo":{"status":"ok","timestamp":1707395022476,"user_tz":-330,"elapsed":3145,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer()"],"metadata":{"id":"M0BmeVyIrG2R","executionInfo":{"status":"ok","timestamp":1707395051326,"user_tz":-330,"elapsed":4,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["tokenizer.fit_on_texts([data])"],"metadata":{"id":"KunvhUqWrOr3","executionInfo":{"status":"ok","timestamp":1707395060892,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["len(tokenizer.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ToQLHcp7rQ5R","executionInfo":{"status":"ok","timestamp":1707395089424,"user_tz":-330,"elapsed":2,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"1052e217-65ae-4514-8141-2500c37e3056"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2571"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["input_sequences = []\n","for sentence in data.split('\\n'):\n","  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n","\n","  for i in range(1,len(tokenized_sentence)):\n","    input_sequences.append(tokenized_sentence[:i+1])"],"metadata":{"id":"FUbot9AsrTTw","executionInfo":{"status":"ok","timestamp":1707395256673,"user_tz":-330,"elapsed":435,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["input_sequences"],"metadata":{"id":"asn_dbyprppK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len = max([len(x) for x in input_sequences])"],"metadata":{"id":"EiheX0ZdsC1C","executionInfo":{"status":"ok","timestamp":1707395302906,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["max_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7SCoMEVsMCB","executionInfo":{"status":"ok","timestamp":1707395309266,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"695afbaf-e6c3-4450-cd9f-4dc335367fdd"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"],"metadata":{"id":"b2RnUyffsNb8","executionInfo":{"status":"ok","timestamp":1707395394540,"user_tz":-330,"elapsed":2,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["padded_input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6X1hp8zsXV_","executionInfo":{"status":"ok","timestamp":1707395395825,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"233804a0-7c8a-47d9-a8a0-b194356c3ee9"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0,    0,    0, ...,    0,  410,  675],\n","       [   0,    0,    0, ...,  410,  675,  326],\n","       [   0,    0,    0, ...,  675,  326,   47],\n","       ...,\n","       [   0,    0,    0, ...,    0, 2571,  127],\n","       [   0,    0,    0, ..., 2571,  127,   85],\n","       [   0,    0,    0, ...,  127,   85,   47]], dtype=int32)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["X = padded_input_sequences[:,:-1]"],"metadata":{"id":"DsHmeh6VsZVC","executionInfo":{"status":"ok","timestamp":1707395405481,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFlfNIl1slCT","executionInfo":{"status":"ok","timestamp":1707395408345,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"80a49bef-a92c-44e4-97d8-9aa9fc27d8f0"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0,    0,    0, ...,    0,    0,  410],\n","       [   0,    0,    0, ...,    0,  410,  675],\n","       [   0,    0,    0, ...,  410,  675,  326],\n","       ...,\n","       [   0,    0,    0, ...,    0,    0, 2571],\n","       [   0,    0,    0, ...,    0, 2571,  127],\n","       [   0,    0,    0, ..., 2571,  127,   85]], dtype=int32)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["y = padded_input_sequences[:,-1]"],"metadata":{"id":"HqXLE5oFslvs","executionInfo":{"status":"ok","timestamp":1707395417923,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvUCaXXosoL7","executionInfo":{"status":"ok","timestamp":1707395422007,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"f52ad22b-f2b9-4424-d799-49fa5eaaa381"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([675, 326,  47, ..., 127,  85,  47], dtype=int32)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtlDxSmYspEv","executionInfo":{"status":"ok","timestamp":1707395447471,"user_tz":-330,"elapsed":2,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"a4f186f8-a703-4d14-b33a-4064f8810a68"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9887, 36)"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"St3aJJgMsvQX","executionInfo":{"status":"ok","timestamp":1707395452212,"user_tz":-330,"elapsed":2,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"ee640011-3a35-434c-ffc6-f0d7f63980ac"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9887,)"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","y = to_categorical(y,num_classes=2572)"],"metadata":{"id":"MQUCFOopswe9","executionInfo":{"status":"ok","timestamp":1707395525664,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ylQn6bNtCZn","executionInfo":{"status":"ok","timestamp":1707395536016,"user_tz":-330,"elapsed":4,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"6d068055-cdd3-4b75-8cb8-837573152ed6"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9887, 2572)"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense"],"metadata":{"id":"y8jbRAGYtE5v","executionInfo":{"status":"ok","timestamp":1707395553535,"user_tz":-330,"elapsed":3,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(2572, 100, input_length=36))\n","model.add(LSTM(150))\n","model.add(Dense(2572, activation='softmax'))"],"metadata":{"id":"_TWIpMy_tJSo","executionInfo":{"status":"ok","timestamp":1707396215071,"user_tz":-330,"elapsed":570,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"],"metadata":{"id":"ktopM2_QtM9b","executionInfo":{"status":"ok","timestamp":1707396217082,"user_tz":-330,"elapsed":2,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dilC3w9otWC4","executionInfo":{"status":"ok","timestamp":1707396219473,"user_tz":-330,"elapsed":681,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"5befdd85-730a-405f-da65-67bfee327629"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, 36, 100)           257200    \n","                                                                 \n"," lstm_4 (LSTM)               (None, 150)               150600    \n","                                                                 \n"," dense_2 (Dense)             (None, 2572)              388372    \n","                                                                 \n","=================================================================\n","Total params: 796172 (3.04 MB)\n","Trainable params: 796172 (3.04 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(X,y,epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJvlaobltXkt","executionInfo":{"status":"ok","timestamp":1707396434498,"user_tz":-330,"elapsed":212119,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"4d8bb492-4186-4acc-a98a-cbada14e2f5b"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","309/309 [==============================] - 17s 46ms/step - loss: 6.9129 - accuracy: 0.0407\n","Epoch 2/100\n","309/309 [==============================] - 3s 9ms/step - loss: 6.4202 - accuracy: 0.0479\n","Epoch 3/100\n","309/309 [==============================] - 3s 9ms/step - loss: 6.1983 - accuracy: 0.0618\n","Epoch 4/100\n","309/309 [==============================] - 2s 8ms/step - loss: 5.9365 - accuracy: 0.0790\n","Epoch 5/100\n","309/309 [==============================] - 2s 7ms/step - loss: 5.6460 - accuracy: 0.0995\n","Epoch 6/100\n","309/309 [==============================] - 2s 6ms/step - loss: 5.3483 - accuracy: 0.1200\n","Epoch 7/100\n","309/309 [==============================] - 2s 8ms/step - loss: 5.0572 - accuracy: 0.1383\n","Epoch 8/100\n","309/309 [==============================] - 2s 6ms/step - loss: 4.7689 - accuracy: 0.1607\n","Epoch 9/100\n","309/309 [==============================] - 3s 9ms/step - loss: 4.4903 - accuracy: 0.1841\n","Epoch 10/100\n","309/309 [==============================] - 2s 6ms/step - loss: 4.2203 - accuracy: 0.2081\n","Epoch 11/100\n","309/309 [==============================] - 2s 6ms/step - loss: 3.9569 - accuracy: 0.2359\n","Epoch 12/100\n","309/309 [==============================] - 2s 5ms/step - loss: 3.7015 - accuracy: 0.2698\n","Epoch 13/100\n","309/309 [==============================] - 2s 5ms/step - loss: 3.4511 - accuracy: 0.3051\n","Epoch 14/100\n","309/309 [==============================] - 2s 7ms/step - loss: 3.2059 - accuracy: 0.3444\n","Epoch 15/100\n","309/309 [==============================] - 2s 7ms/step - loss: 2.9730 - accuracy: 0.3904\n","Epoch 16/100\n","309/309 [==============================] - 2s 7ms/step - loss: 2.7484 - accuracy: 0.4322\n","Epoch 17/100\n","309/309 [==============================] - 2s 6ms/step - loss: 2.5304 - accuracy: 0.4787\n","Epoch 18/100\n","309/309 [==============================] - 2s 6ms/step - loss: 2.3269 - accuracy: 0.5203\n","Epoch 19/100\n","309/309 [==============================] - 2s 6ms/step - loss: 2.1340 - accuracy: 0.5691\n","Epoch 20/100\n","309/309 [==============================] - 2s 5ms/step - loss: 1.9590 - accuracy: 0.6038\n","Epoch 21/100\n","309/309 [==============================] - 2s 6ms/step - loss: 1.7950 - accuracy: 0.6373\n","Epoch 22/100\n","309/309 [==============================] - 3s 8ms/step - loss: 1.6450 - accuracy: 0.6692\n","Epoch 23/100\n","309/309 [==============================] - 2s 5ms/step - loss: 1.5089 - accuracy: 0.6944\n","Epoch 24/100\n","309/309 [==============================] - 2s 6ms/step - loss: 1.3829 - accuracy: 0.7222\n","Epoch 25/100\n","309/309 [==============================] - 2s 6ms/step - loss: 1.2684 - accuracy: 0.7476\n","Epoch 26/100\n","309/309 [==============================] - 2s 6ms/step - loss: 1.1637 - accuracy: 0.7676\n","Epoch 27/100\n","309/309 [==============================] - 2s 6ms/step - loss: 1.0658 - accuracy: 0.7917\n","Epoch 28/100\n","309/309 [==============================] - 2s 7ms/step - loss: 0.9786 - accuracy: 0.8069\n","Epoch 29/100\n","309/309 [==============================] - 2s 8ms/step - loss: 0.8985 - accuracy: 0.8257\n","Epoch 30/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.8263 - accuracy: 0.8420\n","Epoch 31/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.7596 - accuracy: 0.8551\n","Epoch 32/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.6984 - accuracy: 0.8694\n","Epoch 33/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.6442 - accuracy: 0.8781\n","Epoch 34/100\n","309/309 [==============================] - 2s 7ms/step - loss: 0.5957 - accuracy: 0.8875\n","Epoch 35/100\n","309/309 [==============================] - 3s 8ms/step - loss: 0.5516 - accuracy: 0.8935\n","Epoch 36/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.5114 - accuracy: 0.8990\n","Epoch 37/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.4763 - accuracy: 0.9041\n","Epoch 38/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.4451 - accuracy: 0.9104\n","Epoch 39/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.4160 - accuracy: 0.9116\n","Epoch 40/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.3927 - accuracy: 0.9142\n","Epoch 41/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.3677 - accuracy: 0.9203\n","Epoch 42/100\n","309/309 [==============================] - 3s 10ms/step - loss: 0.3481 - accuracy: 0.9199\n","Epoch 43/100\n","309/309 [==============================] - 3s 9ms/step - loss: 0.3306 - accuracy: 0.9215\n","Epoch 44/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.3143 - accuracy: 0.9221\n","Epoch 45/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.3040 - accuracy: 0.9237\n","Epoch 46/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2901 - accuracy: 0.9245\n","Epoch 47/100\n","309/309 [==============================] - 2s 7ms/step - loss: 0.2799 - accuracy: 0.9244\n","Epoch 48/100\n","309/309 [==============================] - 2s 7ms/step - loss: 0.2695 - accuracy: 0.9257\n","Epoch 49/100\n","309/309 [==============================] - 2s 7ms/step - loss: 0.2605 - accuracy: 0.9266\n","Epoch 50/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2537 - accuracy: 0.9271\n","Epoch 51/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2462 - accuracy: 0.9267\n","Epoch 52/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.2407 - accuracy: 0.9272\n","Epoch 53/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2371 - accuracy: 0.9265\n","Epoch 54/100\n","309/309 [==============================] - 2s 7ms/step - loss: 0.2336 - accuracy: 0.9265\n","Epoch 55/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2297 - accuracy: 0.9263\n","Epoch 56/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2250 - accuracy: 0.9261\n","Epoch 57/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.2205 - accuracy: 0.9266\n","Epoch 58/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2167 - accuracy: 0.9275\n","Epoch 59/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2153 - accuracy: 0.9273\n","Epoch 60/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2123 - accuracy: 0.9254\n","Epoch 61/100\n","309/309 [==============================] - 3s 8ms/step - loss: 0.2091 - accuracy: 0.9284\n","Epoch 62/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2086 - accuracy: 0.9280\n","Epoch 63/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2066 - accuracy: 0.9276\n","Epoch 64/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2034 - accuracy: 0.9285\n","Epoch 65/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2016 - accuracy: 0.9271\n","Epoch 66/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.2012 - accuracy: 0.9270\n","Epoch 67/100\n","309/309 [==============================] - 3s 8ms/step - loss: 0.2003 - accuracy: 0.9287\n","Epoch 68/100\n","309/309 [==============================] - 2s 8ms/step - loss: 0.2009 - accuracy: 0.9267\n","Epoch 69/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1991 - accuracy: 0.9256\n","Epoch 70/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1945 - accuracy: 0.9278\n","Epoch 71/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1952 - accuracy: 0.9269\n","Epoch 72/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1933 - accuracy: 0.9281\n","Epoch 73/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1923 - accuracy: 0.9285\n","Epoch 74/100\n","309/309 [==============================] - 2s 7ms/step - loss: 0.1927 - accuracy: 0.9254\n","Epoch 75/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1917 - accuracy: 0.9265\n","Epoch 76/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1897 - accuracy: 0.9275\n","Epoch 77/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1910 - accuracy: 0.9275\n","Epoch 78/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1891 - accuracy: 0.9278\n","Epoch 79/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1891 - accuracy: 0.9260\n","Epoch 80/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1883 - accuracy: 0.9282\n","Epoch 81/100\n","309/309 [==============================] - 2s 8ms/step - loss: 0.1869 - accuracy: 0.9277\n","Epoch 82/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1861 - accuracy: 0.9276\n","Epoch 83/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.1854 - accuracy: 0.9274\n","Epoch 84/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1852 - accuracy: 0.9280\n","Epoch 85/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1857 - accuracy: 0.9279\n","Epoch 86/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1847 - accuracy: 0.9271\n","Epoch 87/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1842 - accuracy: 0.9268\n","Epoch 88/100\n","309/309 [==============================] - 2s 8ms/step - loss: 0.1841 - accuracy: 0.9282\n","Epoch 89/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1988 - accuracy: 0.9265\n","Epoch 90/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.1895 - accuracy: 0.9255\n","Epoch 91/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1841 - accuracy: 0.9284\n","Epoch 92/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.1823 - accuracy: 0.9263\n","Epoch 93/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.1810 - accuracy: 0.9278\n","Epoch 94/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1804 - accuracy: 0.9286\n","Epoch 95/100\n","309/309 [==============================] - 2s 8ms/step - loss: 0.1795 - accuracy: 0.9282\n","Epoch 96/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1802 - accuracy: 0.9278\n","Epoch 97/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1801 - accuracy: 0.9281\n","Epoch 98/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1808 - accuracy: 0.9264\n","Epoch 99/100\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1803 - accuracy: 0.9272\n","Epoch 100/100\n","309/309 [==============================] - 2s 5ms/step - loss: 0.1797 - accuracy: 0.9279\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ce8839cbc10>"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["import time\n","import numpy as np\n","text = \"We propose\"\n","\n","for i in range(10):\n","  # tokenize\n","  token_text = tokenizer.texts_to_sequences([text])[0]\n","  # padding\n","  padded_token_text = pad_sequences([token_text], maxlen=36, padding='pre')\n","  # predict\n","  pos = np.argmax(model.predict(padded_token_text))\n","\n","  for word,index in tokenizer.word_index.items():\n","    if index == pos:\n","      text = text + \" \" + word\n","      print(text)\n","      time.sleep(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86Sjk_JDtbw_","executionInfo":{"status":"ok","timestamp":1707396503645,"user_tz":-330,"elapsed":20738,"user":{"displayName":"15_Aniket Gajare","userId":"14890872111746201754"}},"outputId":"592c6ca2-f68d-4948-ce04-22a05475d021"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 26ms/step\n","We propose to\n","1/1 [==============================] - 0s 17ms/step\n","We propose to identify\n","1/1 [==============================] - 0s 18ms/step\n","We propose to identify sexist\n","1/1 [==============================] - 0s 20ms/step\n","We propose to identify sexist speech\n","1/1 [==============================] - 0s 18ms/step\n","We propose to identify sexist speech on\n","1/1 [==============================] - 0s 18ms/step\n","We propose to identify sexist speech on social\n","1/1 [==============================] - 0s 25ms/step\n","We propose to identify sexist speech on social media\n","1/1 [==============================] - 0s 18ms/step\n","We propose to identify sexist speech on social media using\n","1/1 [==============================] - 0s 17ms/step\n","We propose to identify sexist speech on social media using a\n","1/1 [==============================] - 0s 21ms/step\n","We propose to identify sexist speech on social media using a result\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FijmpTXQwln9"},"execution_count":null,"outputs":[]}]}